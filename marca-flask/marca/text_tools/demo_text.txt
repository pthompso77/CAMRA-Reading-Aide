The current era of digital evolution and increased social engagements results in a large amount of content creation and subsequent propagation [1]. This content may not always be authentic and/or reliable but is often not recognized and reported. Misinformation could be in any form; it could be either willful misinformation, fictional discussions, and non-verifiable information or news. Misinformation often tends to gain immense traction, since most of the times these are rumors surrounding controversial happenings around the globe [2]. It further greatly affects decision-making, especially at the time of crisis where people are trying to use social media platforms for seeking help [3]. The rampant growth in propagation of misleading content makes it extremely difficult for users to identify quality content on these platforms [4]. One of the most popular platforms that catalyzes these rumors is the micro-blogging platform of Twitter, since people use it extensively for sharing their views and opinions. This makes the credibility of content on the platform a matter of great concern [5, 6].

Social media platforms, specifically Twitter, experience several evidences of misinformation and disinformation in the form of rumors, conspiracies, and works of fiction in the current scenario. These stories have created substantial social and political unrest in recent times, which makes it pertinent to address them through policy-level interventions. These platforms are even flooded with memes citing fake stories and crime statistics designed to feed rightist conspiracy theories. Studies also explore the impact of non-verified information on critical events, like the outcome of the 2016 U.S. Presidential election [7]. Another popular event surrounding the Parkland shooting generated a host of hoax and disinformation theories. Several families of the victims were falsely accused and had to face social ostracism. Some doctored tweets even raised questions surrounding racism that led to social unrest.

Academic literature also highlights several instances of misinformation propagation on Twitter in the form of rumors, digital vigilantes, and false flags, amongst which was a popular case of rumors that emerged from Twitter after the 2013 Boston Marathon Bombing [8, 9]. The results from these studies reported that about 29% of the most viral posts turned out to be rumors and misinformation propagated surrounding the crisis. There have been similar instances in the domain of healthcare, politics, and natural disasters. The outbreak of Ebola was another event that triggered a series of false information trails [10]. The findings reported that about 59% of the content was misinformation and amongst that, the most common discussions stated that Ebola could have been cured by the plant Ewedu or by blood transfusion.

In addition to this, the special elections held in Massachusetts in 2010 to fill the Senate seat formerly held by Ted Kennedy also followed a series of misleading posts on social media. Some people consider misinformation that is propagated surrounding politics as mere political graffiti having no serious aftereffects, while there is a majority of the population that feels social media misinformation has the power to alter the voting behavior [11]. Studies also explore the working dynamics of a rumor mill by analyzing Twitter data of Haiti Earthquake 2010 [12] or hurricane Sandy [13]. Findings are indicative of the fact that “anxiety” and “informational ambiguity” are the key drivers behind abnormal patterns of communications under these extreme crisis events. The evidences from the instances surrounding critical events from various domains make it evident that social media platforms, specifically Twitter, are prone to misinformation propagation and virality.

Apart from the already discussed impact of misinformation that have created significant unrest both socially and politically, the academic literature explores several recently published studies that contribute to the misinformation domain. These advancements are both in the computing as well as the non-computing fields. These studies explore the diffusion dynamics using temporal patterns, content, and source [14] and cater to the impact of misinformation in domains as varied as politics [15], medicine [16], and disaster management [17]. The existing studies focus primarily on the content and the source, but none of the studies highlights the network dynamics of misinformation propagation. Further, none of the studies show the correlation between various attributes using case-based analysis.

The propagation rate for misinformation does not solely depend on the content being propagated but also depends on the nature of users sharing it and the communities they are part of. These users could be fake profiles created for the purpose of marketing for greater visibility on different platforms [18]. Further, these users could also be spammers or automated bots retweeting similar content from possibly similar sources repetitively [19, 20]. There are also several content-specific studies in the existing literature surrounding detection of misinformation in the form of rumors [8, 9, 20, 21] and fake news. The current experience study is based on the findings from three separate research studies conducted surrounding misinformation on Twitter. These three cases have been implemented independently and are either communicated or published as separate technical studies. We have attempted to minimize the technical focus of our discussions in this article so that it is readable by a larger audience. The discussion is based on our findings surrounding the misinformation propagators, the nature of the content, and the networks that facilitate such propagation. These cases are based on the detailed studies done by us in the domain. The subsequent sections explore the focus areas for governance and present an overview of the findings from the three case studies followed by the discussions in the form of findings, implications to practice, and subsequently the conclusion.

2 MISINFORMATION
Since the current study is an experience article, the related work surrounding misinformation focuses on derivation of attributes and scenarios that can be used to build the case studies. This section does not compare the existing studies for identification of misinformation or detection of fake profiles. The identified attributes in this section act as the theoretical foundations for the case studies in the subsequent section. The studies in existing literature are primarily surrounding the propagators that possess certain personality dimensions or automated bots that usually repetitively retweet similar content and spam the platforms. The existing studies also focus on content and network attributes for identifying misinformation in social media.

This section explores building blocks for case scenarios that adopt different metrics that can be used for modeling different aspects of misinformation propagation. The sub-sections demonstrates the identification of content attributes that could be identified and analysed for segregating misinformation. This is followed by the user level attributes of misinformation propagators and the properties of the network in which the content is propagated. Extensive amount of existing literature is highly inclined towards the discipline of mass communication and social psychology as a discipline, whereas data scientists have borrowed these theories to examine the domain of misinformation extensively in computer science literature.

2.1 Content Attributes
The primary question surrounding content drivers surrounding misinformation is what makes people unintentionally propagate misinformation or believe that the information is credible and correct. Studies in existing literature surrounding social psychology and judgment claim that any piece of information that aligns with other things that the user assumes to be true is more likely to be accepted by the user [22]. The supporting evidences and the logical compatibility of the content shared is often assessed by the recipient and the more it is consistent with accepted facts and beliefs the more are the chances of its acceptance.
