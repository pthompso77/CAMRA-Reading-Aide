# MARCA
## Memory and Reading Comprehension Aide  
Massive corpora of text data are accruing in the digital realm. In order to properly organize and use this data it must be interpreted by machines and matched to queries. Such queries are largely made using natural language, spoken or written, and natural language contains many indefinite semantics. Understanding the murky semantics is very difficult, and machines alone may not be able to achieve this on their own. We can analyze more in depth by combining the machineâ€™s compute power with the learned experience or generational wisdom of human perception and creation of language; the synthesis of language can be much harder than understanding it. We make progress to provide remedies to these difficult ventures in our composite approach. A sequence-to-sequence recurrent neural network works in harmony evaluating natural language using trained models while also learning from human response and preference. While previous models have been centered around syntactic qualities of word and phrase relations, our method takes a closer look at when this strategy fails. By incorporating natural human perspective into the learning model, we identify traits and features that are not readily identifiable. Our identification of nuanced features, often hidden, contribute to the translation of natural language to machine language. This makes progress in the trajectory that will likely affect communication with machines and the understanding of human perspective and brain function.
